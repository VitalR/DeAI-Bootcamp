import os
from diffusers import StableDiffusionPipeline
import torch

# –°–ø–∏—Å–æ–∫ –ø—Ä–æ–º–ø—Ç–æ–≤
prompts = [
    "a cyberpunk city at night, neon lights, high detail",
    "a fantasy landscape with dragons and floating islands",
    "a cat astronaut floating in space, cartoon style",
    "a medieval village in the morning fog",
    "futuristic AI robot reading a book in a library"
]

# –£–±–µ–¥–∏–º—Å—è, —á—Ç–æ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è –≤—ã–≤–æ–¥–∞ –µ—Å—Ç—å
output_dir = "output"
os.makedirs(output_dir, exist_ok=True)

# –ó–∞–≥—Ä—É–∑–∫–∞ –ø–∞–π–ø–ª–∞–π–Ω–∞
print("‚è≥ Loading model...")
pipe = StableDiffusionPipeline.from_pretrained("runwayml/stable-diffusion-v1-5")
pipe = pipe.to("cpu")  # –∏—Å–ø–æ–ª—å–∑—É–µ–º CPU
print("‚úÖ Model loaded.")

# –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
for idx, prompt in enumerate(prompts, start=1):
    print(f"üé® Generating image {idx}/{len(prompts)}: \"{prompt}\"")
    image = pipe(prompt, num_inference_steps=30).images[0]  # –º–æ–∂–Ω–æ —É–º–µ–Ω—å—à–∏—Ç—å —à–∞–≥–∏ –Ω–∞ CPU
    image_path = os.path.join(output_dir, f"img_{idx}.png")
    image.save(image_path)
    print(f"‚úÖ Saved to {image_path}")

print("\nüèÅ Done generating all images!")
